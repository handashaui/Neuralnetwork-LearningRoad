{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aca6142-e73a-41ef-9c83-f679d92fd5e0",
   "metadata": {},
   "source": [
    "# CNN和ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9584e81-cfbf-4940-8a59-8a46510badde",
   "metadata": {},
   "source": [
    "## 1. 加载相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b833aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/b1/43/28bc858b022f6337326d75f4027d2073aad5432328f01ee1236d847f1b82/torchvision-0.22.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchvision-0.22.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /Users/hanz/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
      "Collecting torch==2.7.0 (from torchvision)\n",
      "  Obtaining dependency information for torch==2.7.0 from https://files.pythonhosted.org/packages/aa/3f/85b56f7e2abcfa558c5fbf7b11eb02d78a4a63e6aeee2bbae3bb552abea5/torch-2.7.0-cp311-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.7.0-cp311-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/hanz/anaconda3/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in /Users/hanz/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.9.0)\n",
      "Collecting typing-extensions>=4.10.0 (from torch==2.7.0->torchvision)\n",
      "  Obtaining dependency information for typing-extensions>=4.10.0 from https://files.pythonhosted.org/packages/8b/54/b1ae86c0973cc6f0210b53d508ca3641fb6d0c56823f288d108bc7ab3cc8/typing_extensions-4.13.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.0->torchvision)\n",
      "  Obtaining dependency information for sympy>=1.13.3 from https://files.pythonhosted.org/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /Users/hanz/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/hanz/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/hanz/anaconda3/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hanz/anaconda3/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hanz/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.7.0->torchvision) (2.1.1)\n",
      "Downloading torchvision-0.22.0-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.0-cp311-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-extensions, sympy, torch, torchvision\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.11.1\n",
      "    Uninstalling sympy-1.11.1:\n",
      "      Successfully uninstalled sympy-1.11.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 typing-extensions-4.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a9125c-bb12-42a6-a37c-9c925b041a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d5339-3134-4b23-bad0-ce3774a5b4d8",
   "metadata": {},
   "source": [
    "## 2. 下载和加载MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680a27c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3968290463.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    torchvision.datasets.\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "torchvision.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6f6e4a-5b46-49ae-b671-59a586963b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "full_train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 划分训练集和验证集（例如：50000 训练 + 10000 验证）\n",
    "train_size = int(0.83 * len(full_train_dataset))  # 50000\n",
    "val_size = len(full_train_dataset) - train_size   # 10000\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84010119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d9794-8513-422c-af50-c93e48faaa74",
   "metadata": {},
   "source": [
    "### 2.1 可视化单张图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ba0181e-175b-4779-9d5e-bd8645e1eeba",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy.random' has no attribute 'randiant'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandiant(o, \u001b[38;5;28mlen\u001b[39m(full_train_dataset))\n\u001b[1;32m      2\u001b[0m image, label \u001b[38;5;241m=\u001b[39m mnist_dataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image\u001b[38;5;241m.\u001b[39msqueeze(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy.random' has no attribute 'randiant'"
     ]
    }
   ],
   "source": [
    "idx = np.random.randiant(o, len(full_train_dataset))\n",
    "image, label = mnist_dataset[0]\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f'Label: {label}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03acb5-ccdb-4833-a9d1-ee3327de6b6e",
   "metadata": {},
   "source": [
    "### 2.2 可视化多张图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38432d1c-6777-48b7-9427-0c81fd8a2c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 14\u001b[0m show_images(mnist_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def show_images(dataset, num_images=25):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(num_images):\n",
    "        image, label = dataset[i]\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(image.squeeze(), cmap='gray')\n",
    "        plt.title(label, fontsize=8)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(mnist_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a386a11-c4b7-439a-99b9-c79d6f699b1f",
   "metadata": {},
   "source": [
    "## 3. 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b974834c-f9c3-4788-af00-2073ed6a16f0",
   "metadata": {},
   "source": [
    "### 3.1 简单的CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd24477-589d-45ce-aa1b-4ebe2313754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [B, 32, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [B, 64, 7, 7]\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7947ef4f-a449-48a7-946a-1ebbe6a18cd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c0c82-83c9-424c-a592-a5e09e70ea72",
   "metadata": {},
   "source": [
    "### 3.2 简化的ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09f69365-dee1-44c4-bf2e-02e013106206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.skip = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.layer1 = BasicBlock(16, 32, stride=2)\n",
    "        self.layer2 = BasicBlock(32, 64, stride=2)\n",
    "        self.fc = nn.Linear(64 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(self.conv(x)))    # [B, 16, 28, 28]\n",
    "        x = self.layer1(x)                   # [B, 32, 14, 14]\n",
    "        x = self.layer2(x)                   # [B, 64, 7, 7]\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29437e-6218-40c1-a5a6-9599079a81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model = ResNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d29ad-73ad-4a1f-9bb4-aff89242ca9d",
   "metadata": {},
   "source": [
    "## 4. 训练过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a823d4-0ffb-4f18-9816-e30da076c098",
   "metadata": {},
   "source": [
    "### 4.1 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4e558a6-3c9c-49a6-8bac-eb76fff31dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, device, epoch, writer):\n",
    "    model.train()\n",
    "    running_loss, correct = 0, 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, targets) in enumerate(loader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = outputs.argmax(dim=1)\n",
    "        correct += (pred == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    print(f\"Epoch {epoch} - Train Loss: {avg_loss:.4f}, Acc: {acc:.4f}\")\n",
    "    writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", acc, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75763425-dab4-422a-891c-fc144acd03a5",
   "metadata": {},
   "source": [
    "### 4.2 验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62bc1c27-05a9-4d61-80b7-13bd7be7b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, device, epoch, writer):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            val_loss += F.cross_entropy(outputs, targets, reduction='sum').item()\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    val_loss /= len(loader.dataset)\n",
    "    val_acc = correct / len(loader.dataset)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_acc, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea047bed-1c6a-460b-baff-a5e1e7b42cdf",
   "metadata": {},
   "source": [
    "### 4.3 测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5b8d8df-c10b-4405-a185-bc52635daac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            test_loss += F.cross_entropy(outputs, targets, reduction='sum').item()\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(loader.dataset)\n",
    "    test_acc = correct / len(loader.dataset)\n",
    "    print(f\"\\n [Test Set] Average loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}\")\n",
    "    return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836c39b-31a3-4339-9742-749d1e9bccfd",
   "metadata": {},
   "source": [
    "### 4.3 训练CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ce6c46ed-762f-4e41-a90c-31ce40d44dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.1462, Acc: 0.9548\n",
      "Validation Loss: 0.0568, Accuracy: 0.9821\n",
      "✅ 模型在 epoch 1 保存，验证准确率: 0.9821\n",
      "Epoch 2 - Train Loss: 0.0468, Acc: 0.9852\n",
      "Validation Loss: 0.0546, Accuracy: 0.9817\n",
      "Epoch 3 - Train Loss: 0.0326, Acc: 0.9898\n",
      "Validation Loss: 0.0434, Accuracy: 0.9874\n",
      "✅ 模型在 epoch 3 保存，验证准确率: 0.9874\n",
      "Epoch 4 - Train Loss: 0.0216, Acc: 0.9930\n",
      "Validation Loss: 0.0421, Accuracy: 0.9862\n",
      "Epoch 5 - Train Loss: 0.0164, Acc: 0.9949\n",
      "Validation Loss: 0.0386, Accuracy: 0.9875\n",
      "✅ 模型在 epoch 5 保存，验证准确率: 0.9875\n",
      "Epoch 6 - Train Loss: 0.0134, Acc: 0.9956\n",
      "Validation Loss: 0.0360, Accuracy: 0.9897\n",
      "✅ 模型在 epoch 6 保存，验证准确率: 0.9897\n",
      "Epoch 7 - Train Loss: 0.0115, Acc: 0.9961\n",
      "Validation Loss: 0.0564, Accuracy: 0.9839\n",
      "Epoch 8 - Train Loss: 0.0107, Acc: 0.9964\n",
      "Validation Loss: 0.0441, Accuracy: 0.9894\n",
      "Epoch 9 - Train Loss: 0.0083, Acc: 0.9972\n",
      "Validation Loss: 0.0480, Accuracy: 0.9879\n",
      "Epoch 10 - Train Loss: 0.0066, Acc: 0.9976\n",
      "Validation Loss: 0.0510, Accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "writer = SummaryWriter(log_dir=\"runs/mnist_CNN\")\n",
    "\n",
    "best_val_acc = 0.0\n",
    "# 训练多个 epoch\n",
    "for epoch in range(1, 11):\n",
    "    train(model, train_loader, optimizer, device, epoch, writer)\n",
    "    validate(model, val_loader, device, epoch, writer)\n",
    "    \n",
    "    # 计算验证准确率\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    # 保存最优模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"CNN_best_model.pth\")\n",
    "        print(f\"✅ 模型在 epoch {epoch} 保存，验证准确率: {val_acc:.4f}\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc04914b-c8a6-4af8-b43d-180af3659da1",
   "metadata": {},
   "source": [
    "### 4.4 测试CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9e093cce-8b3e-4fda-9ba4-0951a2cc4c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Test Set] Average loss: 0.0326, Accuracy: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03261887364387512, 0.9902)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "checkpoint = torch.load('CNN_best_model.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "test(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067a325-4703-4bc6-9b56-dc3776416569",
   "metadata": {},
   "source": [
    "### 4.5 训练ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1a0aaa4f-92b0-4dda-aa36-39c1776c022c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.1209, Acc: 0.9627\n",
      "Validation Loss: 0.0617, Accuracy: 0.9806\n",
      "✅ 模型在 epoch 1 保存，验证准确率: 0.9806\n",
      "Epoch 2 - Train Loss: 0.0433, Acc: 0.9863\n",
      "Validation Loss: 0.0588, Accuracy: 0.9818\n",
      "✅ 模型在 epoch 2 保存，验证准确率: 0.9818\n",
      "Epoch 3 - Train Loss: 0.0290, Acc: 0.9907\n",
      "Validation Loss: 0.0361, Accuracy: 0.9890\n",
      "✅ 模型在 epoch 3 保存，验证准确率: 0.9890\n",
      "Epoch 4 - Train Loss: 0.0220, Acc: 0.9926\n",
      "Validation Loss: 0.0572, Accuracy: 0.9842\n",
      "Epoch 5 - Train Loss: 0.0167, Acc: 0.9943\n",
      "Validation Loss: 0.0413, Accuracy: 0.9873\n",
      "Epoch 6 - Train Loss: 0.0143, Acc: 0.9952\n",
      "Validation Loss: 0.0435, Accuracy: 0.9896\n",
      "✅ 模型在 epoch 6 保存，验证准确率: 0.9896\n",
      "Epoch 7 - Train Loss: 0.0099, Acc: 0.9966\n",
      "Validation Loss: 0.0449, Accuracy: 0.9881\n",
      "Epoch 8 - Train Loss: 0.0112, Acc: 0.9963\n",
      "Validation Loss: 0.0491, Accuracy: 0.9875\n",
      "Epoch 9 - Train Loss: 0.0087, Acc: 0.9970\n",
      "Validation Loss: 0.0516, Accuracy: 0.9881\n",
      "Epoch 10 - Train Loss: 0.0089, Acc: 0.9972\n",
      "Validation Loss: 0.0494, Accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "writer = SummaryWriter(log_dir=\"runs/mnist_ResNet\")\n",
    "\n",
    "best_val_acc = 0.0\n",
    "# 训练多个 epoch\n",
    "for epoch in range(1, 11):\n",
    "    train(model, train_loader, optimizer, device, epoch, writer)\n",
    "    validate(model, val_loader, device, epoch, writer)\n",
    "    \n",
    "    # 计算验证准确率\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    val_acc = correct / len(val_loader.dataset)\n",
    "\n",
    "    # 保存最优模型\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"ResNet_best_model.pth\")\n",
    "        print(f\"✅ 模型在 epoch {epoch} 保存，验证准确率: {val_acc:.4f}\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9200cfb0-40b2-4d3f-b404-d406a6b07718",
   "metadata": {},
   "source": [
    "### 4.6 测试ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "57023b75-24ee-4792-bed9-d0f703fcd195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Test Set] Average loss: 0.0536, Accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05361763286590576, 0.9867)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "checkpoint = torch.load('CNN_best_model.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7932c1bf-2509-454e-b9c1-78b929c07747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (2.12.1)\n",
      "Collecting tensorboard\n",
      "  Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/5d/12/4f70e8e2ba0dbe72ea978429d8530b0333f0ed2140cc571a48802878ef99/tensorboard-2.19.0-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.48.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.24.3)\n",
      "Requirement already satisfied: packaging in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/xpzhang/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m25.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.1\n",
      "    Uninstalling tensorboard-2.12.1:\n",
      "      Successfully uninstalled tensorboard-2.12.1\n",
      "Successfully installed tensorboard-2.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "84cde98b-50a3-4ffb-b971-9702d7eb9bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/20/cf/55b68d5896e58e25f41e5bc826c96678073b512be8ca2b1f4b101e0f195c/tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Using cached tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl (252.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/252.6 MB\u001b[0m \u001b[31m3.9 kB/s\u001b[0m eta \u001b[36m18:09:14\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/http/client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/ssl.py\", line 1311, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/ssl.py\", line 1167, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/req_command.py\", line 248, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 161, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 565, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/operations/prepare.py\", line 479, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Users/xpzhang/anaconda3/lib/python3.11/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139ea4d-bc29-4ea1-97e2-84a6f2c940ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
